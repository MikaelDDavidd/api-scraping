const { createClient } = require('@supabase/supabase-js');
const { config } = require('../config/config');
const { info, warn, error } = require('../utils/logger');

class FastDuplicateChecker {
  constructor() {
    this.supabase = createClient(
      config.supabase.url,
      config.supabase.serviceKey
    );
    
    // Cache em mem√≥ria para verifica√ß√£o ultra-r√°pida
    this.existingPackIds = new Set();
    this.cacheLoaded = false;
    this.lastCacheUpdate = null;
  }

  /**
   * Carrega TODOS os pack IDs existentes em mem√≥ria de uma vez
   * Isso permite verifica√ß√£o O(1) por pack ID
   */
  async loadExistingPacksCache() {
    const startTime = Date.now();
    info('Carregando cache completo de pack IDs existentes...');

    try {
      // üöÄ PAGINA√á√ÉO para buscar TODOS os packs (contornar limite de 1000)
      let allPacks = [];
      let page = 0;
      const pageSize = 1000;
      let hasMore = true;

      while (hasMore) {
        const { data: packs, error: fetchError } = await this.supabase
          .from('packs')
          .select('identifier')
          .order('created_at', { ascending: false })
          .range(page * pageSize, (page + 1) * pageSize - 1);

        if (fetchError) {
          throw fetchError;
        }

        if (packs && packs.length > 0) {
          allPacks.push(...packs);
          info(`P√°gina ${page + 1}: ${packs.length} packs carregados (total: ${allPacks.length})`);
          
          // Se retornou menos que o tamanho da p√°gina, n√£o h√° mais dados
          hasMore = packs.length === pageSize;
          page++;
        } else {
          hasMore = false;
        }
      }

      // Converter para Set para lookup O(1)
      this.existingPackIds = new Set(allPacks.map(p => p.identifier));
      this.cacheLoaded = true;
      this.lastCacheUpdate = Date.now();

      const duration = Date.now() - startTime;
      info(`Cache carregado: ${this.existingPackIds.size} pack IDs em ${duration}ms (${page} p√°ginas)`);
      
      return this.existingPackIds.size;

    } catch (err) {
      error('Erro ao carregar cache de pack IDs', err);
      // Fallback: continuar sem cache (vai usar verifica√ß√£o lenta)
      this.existingPackIds = new Set();
      this.cacheLoaded = false;
      return 0;
    }
  }

  /**
   * Verifica√ß√£o ULTRA-R√ÅPIDA em batch
   * Separa 500 packs em ~1ms ao inv√©s de 500 queries individuais
   */
  async batchCheckDuplicates(packs) {
    if (!packs || packs.length === 0) {
      return { newPacks: [], existingPacks: [] };
    }

    const startTime = Date.now();
    
    // Se cache n√£o carregado, carregar agora
    if (!this.cacheLoaded) {
      await this.loadExistingPacksCache();
    }

    const newPacks = [];
    const existingPacks = [];

    // Verifica√ß√£o O(1) por pack - ULTRA R√ÅPIDA
    for (const pack of packs) {
      if (!pack.packId) {
        warn('Pack sem packId encontrado, ignorando', { pack: pack.name || 'unknown' });
        continue;
      }

      if (this.existingPackIds.has(pack.packId)) {
        existingPacks.push(pack);
      } else {
        newPacks.push(pack);
        // Adicionar ao cache para pr√≥ximas verifica√ß√µes na mesma sess√£o
        this.existingPackIds.add(pack.packId);
      }
    }

    const duration = Date.now() - startTime;
    
    info(`Verifica√ß√£o em batch: ${packs.length} packs em ${duration}ms`, {
      newPacks: newPacks.length,
      existingPacks: existingPacks.length,
      duplicateRate: `${((existingPacks.length / packs.length) * 100).toFixed(1)}%`,
      avgTimePerPack: `${(duration / packs.length).toFixed(2)}ms`
    });

    return { newPacks, existingPacks };
  }

  /**
   * Verifica√ß√£o em lote via database (fallback se cache falhar)
   * Ainda assim muito mais r√°pida que verifica√ß√£o individual
   */
  async batchCheckDuplicatesDB(packIds) {
    const startTime = Date.now();
    
    try {
      // Query √∫nica com todos os IDs
      const { data: existingPacks, error: queryError } = await this.supabase
        .from('packs')
        .select('identifier')
        .in('identifier', packIds);

      if (queryError) {
        throw queryError;
      }

      const existingIds = new Set(existingPacks.map(p => p.identifier));
      const newIds = packIds.filter(id => !existingIds.has(id));

      const duration = Date.now() - startTime;
      info(`Verifica√ß√£o DB batch: ${packIds.length} IDs em ${duration}ms`, {
        existing: existingIds.size,
        new: newIds.length
      });

      return { existingIds, newIds };

    } catch (err) {
      error('Erro na verifica√ß√£o em lote no DB', err);
      return { existingIds: new Set(), newIds: packIds };
    }
  }

  /**
   * Verifica√ß√£o h√≠brida: cache + DB para casos edge
   */
  async hybridBatchCheck(packs) {
    // 1. Primeiro usar cache em mem√≥ria (ultra-r√°pido)
    const cacheResult = await this.batchCheckDuplicates(packs);
    
    // 2. Se cache muito desatualizado (>1h), fazer verifica√ß√£o adicional no DB
    const cacheAge = Date.now() - (this.lastCacheUpdate || 0);
    const oneHour = 60 * 60 * 1000;
    
    if (cacheAge > oneHour && cacheResult.newPacks.length > 0) {
      info('Cache antigo, fazendo verifica√ß√£o adicional no DB...');
      
      const newPackIds = cacheResult.newPacks.map(p => p.packId);
      const dbResult = await this.batchCheckDuplicatesDB(newPackIds);
      
      // Ajustar resultado baseado na verifica√ß√£o do DB
      const finalNewPacks = cacheResult.newPacks.filter(p => 
        dbResult.newIds.includes(p.packId)
      );
      
      const additionalExisting = cacheResult.newPacks.filter(p => 
        !dbResult.newIds.includes(p.packId)
      );
      
      info(`Verifica√ß√£o h√≠brida: ${additionalExisting.length} packs eram duplicados no DB`);
      
      return {
        newPacks: finalNewPacks,
        existingPacks: [...cacheResult.existingPacks, ...additionalExisting]
      };
    }
    
    return cacheResult;
  }

  /**
   * Processar packs em chunks para melhor performance
   */
  async processPacksInChunks(allPacks, chunkSize = 100) {
    const results = {
      allNewPacks: [],
      allExistingPacks: [],
      totalProcessed: 0,
      chunksProcessed: 0
    };

    for (let i = 0; i < allPacks.length; i += chunkSize) {
      const chunk = allPacks.slice(i, i + chunkSize);
      const chunkResult = await this.batchCheckDuplicates(chunk);
      
      results.allNewPacks.push(...chunkResult.newPacks);
      results.allExistingPacks.push(...chunkResult.existingPacks);
      results.totalProcessed += chunk.length;
      results.chunksProcessed++;

      // Log de progresso a cada chunk
      if (results.chunksProcessed % 5 === 0 || i + chunkSize >= allPacks.length) {
        info(`Progresso verifica√ß√£o: ${results.totalProcessed}/${allPacks.length} packs`, {
          newFound: results.allNewPacks.length,
          duplicates: results.allExistingPacks.length,
          chunksProcessed: results.chunksProcessed
        });
      }
    }

    return results;
  }

  /**
   * Atualizar cache com novos packs processados
   */
  updateCacheWithNewPacks(newPackIds) {
    newPackIds.forEach(id => this.existingPackIds.add(id));
    info(`Cache atualizado com ${newPackIds.length} novos pack IDs`);
  }

  /**
   * Limpar cache (para testes ou reset)
   */
  clearCache() {
    this.existingPackIds.clear();
    this.cacheLoaded = false;
    this.lastCacheUpdate = null;
    info('Cache de pack IDs limpo');
  }

  /**
   * Estat√≠sticas do cache
   */
  getCacheStats() {
    return {
      cacheLoaded: this.cacheLoaded,
      cachedPackIds: this.existingPackIds.size,
      lastUpdate: this.lastCacheUpdate,
      cacheAge: this.lastCacheUpdate ? Date.now() - this.lastCacheUpdate : null
    };
  }

  /**
   * Verifica√ß√£o super r√°pida de um √∫nico pack (O(1))
   */
  isPackDuplicate(packId) {
    return this.existingPackIds.has(packId);
  }

  /**
   * Benchmark da verifica√ß√£o
   */
  async benchmarkDuplicateCheck(testPacks) {
    console.log('üèÅ BENCHMARK: Verifica√ß√£o de Duplicados\n');

    // Preparar dados de teste
    const packIds = testPacks.map(p => p.packId).slice(0, 1000); // M√°ximo 1000 para teste

    console.log(`Testando com ${packIds.length} packs...\n`);

    // 1. M√©todo antigo (simulado): verifica√ß√£o individual
    console.log('1Ô∏è‚É£ M√©todo individual (simulado):');
    const oldStart = Date.now();
    // Simular delay de query individual (2ms por pack)
    await new Promise(resolve => setTimeout(resolve, packIds.length * 2));
    const oldDuration = Date.now() - oldStart;
    console.log(`   Tempo: ${oldDuration}ms (${(oldDuration/packIds.length).toFixed(2)}ms por pack)`);

    // 2. M√©todo novo: batch em mem√≥ria
    console.log('\n2Ô∏è‚É£ M√©todo batch em mem√≥ria:');
    const newStart = Date.now();
    const result = await this.batchCheckDuplicates(testPacks);
    const newDuration = Date.now() - newStart;
    console.log(`   Tempo: ${newDuration}ms (${(newDuration/packIds.length).toFixed(2)}ms por pack)`);
    console.log(`   Resultado: ${result.newPacks.length} novos, ${result.existingPacks.length} duplicados`);

    // 3. Compara√ß√£o
    console.log('\nüìä COMPARA√á√ÉO:');
    const improvement = ((oldDuration - newDuration) / oldDuration * 100).toFixed(1);
    const speedup = (oldDuration / newDuration).toFixed(1);
    console.log(`   Melhoria: ${improvement}% mais r√°pido`);
    console.log(`   Speedup: ${speedup}x mais veloz`);
    console.log(`   Economia de tempo: ${oldDuration - newDuration}ms`);

    return {
      oldDuration,
      newDuration,
      improvement: parseFloat(improvement),
      speedup: parseFloat(speedup)
    };
  }
}

module.exports = FastDuplicateChecker;